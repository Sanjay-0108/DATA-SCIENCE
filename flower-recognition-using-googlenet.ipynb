{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017396,
     "end_time": "2021-03-02T02:59:56.707352",
     "exception": false,
     "start_time": "2021-03-02T02:59:56.689956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Flower Recogntion System using GoogleNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015891,
     "end_time": "2021-03-02T02:59:56.739346",
     "exception": false,
     "start_time": "2021-03-02T02:59:56.723455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Image-based object classification has always been a hot topic in AI filed, especially using different variation of CNN models to perform better to classifiy an image correctly to a category. In this notebook, one of the variation is used, which is GoogleNet. \n",
    "\n",
    "The topic of flower recognition is chosen as flowers have several features of the same species. For example, daisy can have different petal length and width, colours, and radius of pistil, but as human, we know for a fact that it is a daisy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015824,
     "end_time": "2021-03-02T02:59:56.772195",
     "exception": false,
     "start_time": "2021-03-02T02:59:56.756371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Contents:\n",
    "\n",
    "1. [Import libraries and data](#import)\n",
    "\n",
    "2. [Split the data into training, testing and validation](#splitting)\n",
    "\n",
    "3. [Build the model](#model-building)\n",
    "\n",
    "4. [Model evaluation](#model-evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015353,
     "end_time": "2021-03-02T02:59:56.803117",
     "exception": false,
     "start_time": "2021-03-02T02:59:56.787764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='import'></a>\n",
    "## Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T02:59:56.842519Z",
     "iopub.status.busy": "2021-03-02T02:59:56.841734Z",
     "iopub.status.idle": "2021-03-02T03:00:01.740075Z",
     "shell.execute_reply": "2021-03-02T03:00:01.739062Z"
    },
    "id": "qdQkULX86yCB",
    "papermill": {
     "duration": 4.921761,
     "end_time": "2021-03-02T03:00:01.740255",
     "exception": false,
     "start_time": "2021-03-02T02:59:56.818494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024513,
     "end_time": "2021-03-02T03:00:01.790048",
     "exception": false,
     "start_time": "2021-03-02T03:00:01.765535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The target size used cannot be smaller than (224,224) as it will affect the calculations in the GoogleNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:00:01.863419Z",
     "iopub.status.busy": "2021-03-02T03:00:01.862525Z",
     "iopub.status.idle": "2021-03-02T03:00:52.664791Z",
     "shell.execute_reply": "2021-03-02T03:00:52.663555Z"
    },
    "id": "8Pf77EbD7JWD",
    "papermill": {
     "duration": 50.850315,
     "end_time": "2021-03-02T03:00:52.664926",
     "exception": false,
     "start_time": "2021-03-02T03:00:01.814611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "daisy = glob.glob('../input/flowers/Flowers/daisy/*.*')\n",
    "dandelion = glob.glob('../input/flowers/Flowers/dandelion/*.*')\n",
    "rose = glob.glob('../input/flowers/Flowers/rose/*.*')\n",
    "sunflower = glob.glob('../input/flowers/Flowers/sunflower/*.*')\n",
    "tulip = glob.glob('../input/flowers/Flowers/tulip/*.*')\n",
    "\n",
    "data=[]\n",
    "labels = []\n",
    "\n",
    "for i in daisy:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(0)\n",
    "for i in dandelion:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(1)\n",
    "for i in rose:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(2)\n",
    "for i in sunflower:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(3)\n",
    "for i in tulip:   \n",
    "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', target_size= (224,224))\n",
    "    image=np.array(image)\n",
    "    data.append(image)\n",
    "    labels.append(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:00:52.703877Z",
     "iopub.status.busy": "2021-03-02T03:00:52.702602Z",
     "iopub.status.idle": "2021-03-02T03:00:52.937286Z",
     "shell.execute_reply": "2021-03-02T03:00:52.936692Z"
    },
    "id": "VBTZfn708jZT",
    "papermill": {
     "duration": 0.255763,
     "end_time": "2021-03-02T03:00:52.937407",
     "exception": false,
     "start_time": "2021-03-02T03:00:52.681644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015827,
     "end_time": "2021-03-02T03:00:52.969983",
     "exception": false,
     "start_time": "2021-03-02T03:00:52.954156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are a total of 4934 images. Once appended, the size is (224,224,3). 3 refers to its RGB value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:00:53.009636Z",
     "iopub.status.busy": "2021-03-02T03:00:53.008919Z",
     "iopub.status.idle": "2021-03-02T03:00:53.012856Z",
     "shell.execute_reply": "2021-03-02T03:00:53.013330Z"
    },
    "executionInfo": {
     "elapsed": 55871,
     "status": "ok",
     "timestamp": 1599378891922,
     "user": {
      "displayName": "LIM ZHOU YI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggf0QP0iPbdmqdfn-l2xWJMTWl4y879etwASuhD8A=s64",
      "userId": "11540403391242693515"
     },
     "user_tz": -480
    },
    "id": "c5oi-FnK8zKR",
    "outputId": "d2c12f3f-0f91-40e7-f168-73a7383233e1",
    "papermill": {
     "duration": 0.027073,
     "end_time": "2021-03-02T03:00:53.013438",
     "exception": false,
     "start_time": "2021-03-02T03:00:52.986365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017346,
     "end_time": "2021-03-02T03:00:53.047979",
     "exception": false,
     "start_time": "2021-03-02T03:00:53.030633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='splitting'></a>\n",
    "## Split the data into training, testing and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016884,
     "end_time": "2021-03-02T03:00:53.081854",
     "exception": false,
     "start_time": "2021-03-02T03:00:53.064970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The data is splitted into training, testing and validation set. The ratio of training, testing and validation set is 6:2:2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:00:53.120567Z",
     "iopub.status.busy": "2021-03-02T03:00:53.119878Z",
     "iopub.status.idle": "2021-03-02T03:00:54.046543Z",
     "shell.execute_reply": "2021-03-02T03:00:54.045532Z"
    },
    "id": "-5Y-e_JC_oW0",
    "papermill": {
     "duration": 0.947887,
     "end_time": "2021-03-02T03:00:54.046666",
     "exception": false,
     "start_time": "2021-03-02T03:00:53.098779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split into training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.4,\n",
    "                                                random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017403,
     "end_time": "2021-03-02T03:00:54.081852",
     "exception": false,
     "start_time": "2021-03-02T03:00:54.064449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After splitting, all of the images in the training, testing and validation sets have to be normalized (divide by 255). Normalization helps to convert an input image to values that are more familiar to the senses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:00:54.125418Z",
     "iopub.status.busy": "2021-03-02T03:00:54.123649Z",
     "iopub.status.idle": "2021-03-02T03:00:56.080126Z",
     "shell.execute_reply": "2021-03-02T03:00:56.079571Z"
    },
    "id": "wAdNENy3Ake1",
    "papermill": {
     "duration": 1.981357,
     "end_time": "2021-03-02T03:00:56.080235",
     "exception": false,
     "start_time": "2021-03-02T03:00:54.098878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into validation set and testing set\n",
    "X_valid,X_test,y_valid,y_test=train_test_split(X_test,y_test,test_size=0.5,random_state=42)\n",
    "\n",
    "X_train=X_train/255\n",
    "X_test=X_test/255\n",
    "X_valid=X_valid/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:00:56.122868Z",
     "iopub.status.busy": "2021-03-02T03:00:56.121877Z",
     "iopub.status.idle": "2021-03-02T03:00:56.127985Z",
     "shell.execute_reply": "2021-03-02T03:00:56.128713Z"
    },
    "executionInfo": {
     "elapsed": 58607,
     "status": "ok",
     "timestamp": 1599378894687,
     "user": {
      "displayName": "LIM ZHOU YI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggf0QP0iPbdmqdfn-l2xWJMTWl4y879etwASuhD8A=s64",
      "userId": "11540403391242693515"
     },
     "user_tz": -480
    },
    "id": "3C6Rng9yAmY8",
    "outputId": "7beb6a39-402f-4580-82c2-deac6709e9ff",
    "papermill": {
     "duration": 0.03028,
     "end_time": "2021-03-02T03:00:56.128899",
     "exception": false,
     "start_time": "2021-03-02T03:00:56.098619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Training set: \",X_train.shape)\n",
    "print(\"Validation set: \",X_valid.shape)\n",
    "print(\"Testing set: \",X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018331,
     "end_time": "2021-03-02T03:00:56.166646",
     "exception": false,
     "start_time": "2021-03-02T03:00:56.148315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='model-building'></a>\n",
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:00:56.221202Z",
     "iopub.status.busy": "2021-03-02T03:00:56.220180Z",
     "iopub.status.idle": "2021-03-02T03:00:56.243945Z",
     "shell.execute_reply": "2021-03-02T03:00:56.243446Z"
    },
    "id": "_NZGzo0MBGcF",
    "papermill": {
     "duration": 0.059797,
     "end_time": "2021-03-02T03:00:56.244050",
     "exception": false,
     "start_time": "2021-03-02T03:00:56.184253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "def inception(x, filters):\n",
    "    # 1x1\n",
    "    path1 = Conv2D(filters=filters[0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
    "\n",
    "    # 1x1->3x3\n",
    "    path2 = Conv2D(filters=filters[1][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
    "    path2 = Conv2D(filters=filters[1][1], kernel_size=(3,3), strides=1, padding='same', activation='relu')(path2)\n",
    "    \n",
    "    # 1x1->5x5\n",
    "    path3 = Conv2D(filters=filters[2][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
    "    path3 = Conv2D(filters=filters[2][1], kernel_size=(5,5), strides=1, padding='same', activation='relu')(path3)\n",
    "\n",
    "    # 3x3->1x1\n",
    "    path4 = MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(x)\n",
    "    path4 = Conv2D(filters=filters[3], kernel_size=(1,1), strides=1, padding='same', activation='relu')(path4)\n",
    "\n",
    "    return Concatenate(axis=-1)([path1,path2,path3,path4])\n",
    "\n",
    "\n",
    "def auxiliary(x, name=None):\n",
    "    layer = AveragePooling2D(pool_size=(5,5), strides=3, padding='valid')(x)\n",
    "    layer = Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=256, activation='relu',kernel_regularizer=regularizers.l2(0.0001))(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(units=CLASS_NUM, activation='softmax', name=name)(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def googlenet():\n",
    "    layer_in = Input(shape=IMAGE_SHAPE)\n",
    "    \n",
    "    # stage-1\n",
    "    layer = Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', activation='relu')(layer_in)\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "\n",
    "    # stage-2\n",
    "    layer = Conv2D(filters=64, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = Conv2D(filters=192, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "\n",
    "    # stage-3\n",
    "    layer = inception(layer, [ 64,  (96,128), (16,32), 32]) #3a\n",
    "    layer = inception(layer, [128, (128,192), (32,96), 64]) #3b\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    \n",
    "    # stage-4\n",
    "    layer = inception(layer, [192,  (96,208),  (16,48),  64]) #4a\n",
    "    aux1  = auxiliary(layer, name='aux1')\n",
    "    layer = inception(layer, [160, (112,224),  (24,64),  64]) #4b\n",
    "    layer = inception(layer, [128, (128,256),  (24,64),  64]) #4c\n",
    "    layer = inception(layer, [112, (144,288),  (32,64),  64]) #4d\n",
    "    aux2  = auxiliary(layer, name='aux2')\n",
    "    layer = inception(layer, [256, (160,320), (32,128), 128]) #4e\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    \n",
    "    # stage-5\n",
    "    layer = inception(layer, [256, (160,320), (32,128), 128]) #5a\n",
    "    layer = inception(layer, [384, (192,384), (48,128), 128]) #5b\n",
    "    layer = AveragePooling2D(pool_size=(7,7), strides=1, padding='valid')(layer)\n",
    "    \n",
    "    # stage-6\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(units=256, activation='linear',kernel_regularizer=regularizers.l2(0.0001))(layer)\n",
    "    main = Dense(units=CLASS_NUM, activation='softmax', name='main')(layer)\n",
    "    \n",
    "    model = Model(inputs=layer_in, outputs=[main, aux1, aux2])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:00:56.286114Z",
     "iopub.status.busy": "2021-03-02T03:00:56.285348Z",
     "iopub.status.idle": "2021-03-02T03:00:56.288550Z",
     "shell.execute_reply": "2021-03-02T03:00:56.287976Z"
    },
    "id": "lMdKtscWBZsr",
    "papermill": {
     "duration": 0.025884,
     "end_time": "2021-03-02T03:00:56.288660",
     "exception": false,
     "start_time": "2021-03-02T03:00:56.262776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CLASS_NUM = 5\n",
    "BATCH_SIZE = 16\n",
    "EPOCH_STEPS = int(X_train.shape[0]/BATCH_SIZE)\n",
    "IMAGE_SHAPE = (224, 224, 3)\n",
    "MODEL_NAME = 'googlenet_flower.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:00:56.334634Z",
     "iopub.status.busy": "2021-03-02T03:00:56.333978Z",
     "iopub.status.idle": "2021-03-02T03:04:40.628574Z",
     "shell.execute_reply": "2021-03-02T03:04:40.627245Z"
    },
    "executionInfo": {
     "elapsed": 291853,
     "status": "ok",
     "timestamp": 1599379127951,
     "user": {
      "displayName": "LIM ZHOU YI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggf0QP0iPbdmqdfn-l2xWJMTWl4y879etwASuhD8A=s64",
      "userId": "11540403391242693515"
     },
     "user_tz": -480
    },
    "id": "TP9LnG9CBf6L",
    "outputId": "d971ff5d-cfc5-4738-a404-0da2135d5ba0",
    "papermill": {
     "duration": 224.321162,
     "end_time": "2021-03-02T03:04:40.628708",
     "exception": false,
     "start_time": "2021-03-02T03:00:56.307546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "model = googlenet()\n",
    "model.summary()\n",
    "#model.load_weights(MODEL_NAME)\n",
    "tf.keras.utils.plot_model(model, 'GoogLeNet.png')\n",
    "\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "#optimizer = SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "optimizer = ['Adam', 'SGD', 'Adam', 'SGD']\n",
    "epochs = [20, 30, 20, 30]\n",
    "history_all = {}\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs=20,steps_per_epoch=EPOCH_STEPS,validation_data=(X_valid,y_valid))\n",
    "\n",
    "model.save(MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.253542,
     "end_time": "2021-03-02T03:04:43.148701",
     "exception": false,
     "start_time": "2021-03-02T03:04:41.895159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id='model-evaluation'></a>\n",
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:04:45.655007Z",
     "iopub.status.busy": "2021-03-02T03:04:45.654202Z",
     "iopub.status.idle": "2021-03-02T03:04:47.612562Z",
     "shell.execute_reply": "2021-03-02T03:04:47.611235Z"
    },
    "executionInfo": {
     "elapsed": 293450,
     "status": "ok",
     "timestamp": 1599379129556,
     "user": {
      "displayName": "LIM ZHOU YI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggf0QP0iPbdmqdfn-l2xWJMTWl4y879etwASuhD8A=s64",
      "userId": "11540403391242693515"
     },
     "user_tz": -480
    },
    "id": "v9CvWlQqCnnj",
    "outputId": "0a404f41-e469-4c28-8b47-184f23db76da",
    "papermill": {
     "duration": 3.214876,
     "end_time": "2021-03-02T03:04:47.612724",
     "exception": false,
     "start_time": "2021-03-02T03:04:44.397848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('Score:', score[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:04:50.323597Z",
     "iopub.status.busy": "2021-03-02T03:04:50.322897Z",
     "iopub.status.idle": "2021-03-02T03:04:50.597583Z",
     "shell.execute_reply": "2021-03-02T03:04:50.596937Z"
    },
    "executionInfo": {
     "elapsed": 294362,
     "status": "ok",
     "timestamp": 1599379130477,
     "user": {
      "displayName": "LIM ZHOU YI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggf0QP0iPbdmqdfn-l2xWJMTWl4y879etwASuhD8A=s64",
      "userId": "11540403391242693515"
     },
     "user_tz": -480
    },
    "id": "sBfO2d1cOGUD",
    "outputId": "1bf8f035-9384-48c6-8598-709d6661091b",
    "papermill": {
     "duration": 1.548109,
     "end_time": "2021-03-02T03:04:50.597702",
     "exception": false,
     "start_time": "2021-03-02T03:04:49.049593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['main_accuracy'])\n",
    "plt.plot(history.history['val_main_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-02T03:04:53.139545Z",
     "iopub.status.busy": "2021-03-02T03:04:53.133161Z",
     "iopub.status.idle": "2021-03-02T03:04:53.315663Z",
     "shell.execute_reply": "2021-03-02T03:04:53.316176Z"
    },
    "executionInfo": {
     "elapsed": 294357,
     "status": "ok",
     "timestamp": 1599379130479,
     "user": {
      "displayName": "LIM ZHOU YI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggf0QP0iPbdmqdfn-l2xWJMTWl4y879etwASuhD8A=s64",
      "userId": "11540403391242693515"
     },
     "user_tz": -480
    },
    "id": "2yw5q-hOO0Sf",
    "outputId": "48c2aebe-9380-40ae-b928-7483ceb6d98e",
    "papermill": {
     "duration": 1.43148,
     "end_time": "2021-03-02T03:04:53.316329",
     "exception": false,
     "start_time": "2021-03-02T03:04:51.884849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['main_loss'])\n",
    "plt.plot(history.history['val_main_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.23767,
     "end_time": "2021-03-02T03:04:55.783993",
     "exception": false,
     "start_time": "2021-03-02T03:04:54.546323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 306.028618,
   "end_time": "2021-03-02T03:04:58.672375",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-02T02:59:52.643757",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
